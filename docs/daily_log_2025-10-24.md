# 작업 일지 - 2025년 10월 24일

## 📋 작업 요약

오늘은 **GRIP 조건 강화** 및 **조인트 구조 분석**에 집중했습니다.

---

## 🎯 주요 성과

### 1. GRIP 조건 강화 (v3.8.0 → v3.8.1) ✅

**문제 발견**:
- 300K 학습 후 GRIP 38%, LIFT 0%
- GUI 확인 결과: 로봇이 큐브 5cm 거리에서 "성공" 판정
- 실제로는 큐브를 잡지 못함 (False Positive)

**해결**:
```python
# 이전 (v3.8.0)
grasp_valid = (
    dist_to_cube < 0.05 and           # 5cm
    0.025 < gripper_width < 0.060 and # 2.5-6.0cm
    abs(z_offset) < 0.02              # 2cm
)

# 현재 (v3.8.1)
grasp_valid = (
    dist_to_cube < 0.03 and           # 3cm (-40%)
    0.030 < gripper_width < 0.050 and # 3.0-5.0cm (±0.5cm)
    abs(z_offset) < 0.015             # 1.5cm (-25%)
)
```

**영향**:
- 조건이 3배 엄격해짐
- 실제 물리적 잡기 가능하도록 설계
- 초기 성공률 저하 예상 (38% → 0% → 점진적 증가)

### 2. 조인트 구조 문제 발견 🔍

**분석 결과**:
- 실제 RoArm-M3: **5+1 DOF** (6개 조인트)
  * BASE, SHOULDER, ELBOW, WRIST, ROLL + GRIPPER
  
- 현재 URDF: **6+2 DOF** (8개 조인트)
  * joint_1 ~ joint_6 + gripper_left + gripper_right
  * **joint_6의 정체 불명** ⚠️

**의심 사항**:
```
joint_6:
  - Parent: link_5
  - Child: gripper_base
  - Type: revolute (Z축 회전)
  - Range: -90° ~ +90°
  - 문제: 실제 로봇에는 없는 조인트
```

**추가 문제**:
```
joint_4 (WRIST):
  - URDF: -180° ~ +180°
  - 실제: -90° ~ +90°
  - 영향: 학습 시 불가능한 자세 탐색
```

### 3. 문서화 완료 📝

**생성된 문서**:

1. **`docs/v3.8.1_grip_strengthening_plan.md`**
   - GRIP 조건 강화 상세 설명
   - 보상 구조 완전 분석
   - 학습 전략 및 예상 진행
   - AI 교차 검증 요청사항

2. **`docs/joint_comparison_analysis.md`**
   - 실제 vs URDF 조인트 비교
   - joint_6 문제 분석
   - 해결 방안 3가지 제시
   - 검증 계획

3. **`scripts/rl/check_joint_structure.py`**
   - 조인트 구조 진단 도구
   - joint_6 움직임 테스트
   - GUI 기반 시각적 검증

---

## 🔬 진행 중인 학습

### v3.8.1 학습 현황

```yaml
시작 시간: 2025-10-24 20:50
목표: 300,000 timesteps
현재: 5,000 timesteps (1.7%)
예상 완료: 21:05 (약 15분 소요)

초기 지표:
  GRIP: 0% (예상대로, 조건 강화)
  REACH: 0% (초기 탐색 단계)
  LIFT: 0%
  평균 보상: 2,310
  FPS: 384
```

### 학습 파라미터

```python
Algorithm: PPO
Learning Rate: 3e-4
Batch Size: 64
N-steps: 2048
Entropy: 0.01
```

---

## 📊 이전 학습 결과 (v3.8.0)

| Timesteps | REACH | GRIP | LIFT | 비고 |
|-----------|-------|------|------|------|
| 100K | 40% | 0% | 0% | 초기 학습 |
| 300K | 49% | 38% | 0% | GRIP 조건 너무 느슨 |

**문제점**:
- GRIP 38%이지만 실제로 큐브 안 잡음
- 로그상으로만 성공 (dist=4.6cm에서 +50 보상)
- LIFT 불가능 (물리적 attachment 안 됨)

---

## 🔧 기술적 개선사항

### 1. 환경 코드 수정

**파일**: `envs/roarm_pick_place_env.py`

```python
# Lines 860-870: GRIP 조건 강화
is_grasping_cube = (0.030 < gripper_width < 0.050)  # 3-5cm
grasp_valid = (
    dist_to_cube < 0.03 and              # 3cm
    is_grasping_cube and
    abs(cube_relative_to_ee[2]) < 0.015  # 1.5cm
)

# Lines 990-1010: PERFECT GRIP 조건
if dist_to_cube < 0.02 and abs(cube_relative_to_ee[2]) < 0.008:
    reward += 100.0  # PERFECT GRIP
```

### 2. 학습 스크립트 개선

**파일**: `scripts/rl/train_dense_reward.py`

- `--resume` 인자 추가 (모델 경로)
- `--resume-vecnorm` 인자 추가 (통계 파일 경로)
- VecNormalize 로딩 로직 구현

### 3. 진단 도구 추가

**파일**: `scripts/rl/check_joint_structure.py`

- Isaac Sim GUI에서 각 조인트 개별 테스트
- joint_6 움직임 시각화
- 그리퍼 동작 확인

---

## 🎓 학습한 내용

### 1. GRIP 조건 설계의 중요성

```
느슨한 조건 (5cm):
  ✓ 빠른 학습
  ✗ False Positive (가짜 성공)
  ✗ 실제 태스크 불가능

엄격한 조건 (3cm):
  ✗ 느린 초기 학습
  ✓ 진짜 성공 (True Positive)
  ✓ 실제 로봇 전이 가능
```

### 2. Visual Verification의 필수성

- 로그 지표만으로는 불충분
- GUI 재생으로 실제 행동 확인 필요
- "dist=0.046m, GRIP +50" → 실제로는 실패

### 3. URDF와 실제 로봇의 괴리

- URDF가 실제 로봇과 다를 수 있음
- joint_6 같은 불필요한 조인트 존재 가능
- 제조사 스펙과 대조 필요

---

## 🚀 다음 단계

### 즉시 수행 (학습 완료 후)

1. **GUI 검증** ⚠️ 최우선
   ```bash
   ~/isaacsim/python.sh scripts/rl/replay_roarm_gui.py \
     --model logs/rl_training_curriculum/final_model/roarm_ppo_dense_final.zip \
     --vecnorm logs/rl_training_curriculum/final_model/vecnormalize.pkl \
     --episodes 5
   ```
   - GRIP 달성 시 큐브가 실제로 들리는지 확인
   - v3.8.0 (38% 가짜) vs v3.8.1 (예상 20-30% 진짜)

2. **조인트 구조 검증**
   ```bash
   ~/isaacsim/python.sh scripts/rl/check_joint_structure.py
   ```
   - joint_6이 실제로 움직이는지
   - 움직임의 의미가 있는지
   - URDF 수정 필요 여부 판단

### 단기 목표 (1-2일)

1. **v3.8.1 학습 완료 분석**
   - 300K 학습 결과 평가
   - GRIP/LIFT 달성 여부
   - 필요시 500K 연장

2. **URDF 수정 (v3.8.2)**
   - joint_6 처리 (제거 or fixed)
   - joint_4 범위 수정 (±180° → ±90°)
   - Isaac Sim 임포트 테스트

3. **재학습 (v3.8.2 환경)**
   - 수정된 URDF로 300K 학습
   - 조인트 개수 감소로 학습 효율 향상 기대

### 중기 목표 (1주일)

1. **Curriculum Learning 도입**
   - Phase 0: 쉬운 조건 (5cm)
   - Phase 1: 보통 조건 (4cm)
   - Phase 2: 어려운 조건 (3cm)

2. **Hyperparameter Tuning**
   - Entropy 계수 조정
   - 보상 scale 최적화
   - 학습률 스케줄링

3. **실제 로봇 준비**
   - Sim-to-Real 전략 수립
   - Domain Randomization 적용
   - 실제 로봇 테스트 계획

---

## 📁 변경된 파일 목록

### 수정된 파일

```
envs/roarm_pick_place_env.py
  - Lines 860-870: GRIP 조건 강화
  - Lines 990-1010: PERFECT GRIP 조건 강화
  
scripts/rl/train_dense_reward.py
  - --resume, --resume-vecnorm 인자 추가
  - VecNormalize 로딩 로직 구현
```

### 새로 생성된 파일

```
docs/v3.8.1_grip_strengthening_plan.md
  - GRIP 강화 상세 계획
  - 보상 구조 분석
  - AI 검증 요청사항
  
docs/joint_comparison_analysis.md
  - 조인트 구조 비교
  - joint_6 문제 분석
  - 해결 방안 제시
  
docs/daily_log_2025-10-24.md
  - 오늘 작업 종합 정리
  
scripts/rl/check_joint_structure.py
  - 조인트 진단 도구
  - GUI 기반 시각적 검증
```

---

## 💾 체크포인트

### v3.8.0 (이전 버전)

```
logs/rl_training_curriculum/checkpoints/
  - roarm_ppo_curriculum_300000_steps.zip (182 KB)
  - roarm_ppo_curriculum_vecnormalize_300000_steps.pkl (2.2 KB)

결과: REACH 49%, GRIP 38%, LIFT 0%
문제: GRIP 조건 너무 느슨
```

### v3.8.1 (현재 버전)

```
현재 학습 중: 5K / 300K
예상 저장 위치:
  - logs/rl_training_curriculum/final_model/roarm_ppo_dense_final.zip
  - logs/rl_training_curriculum/final_model/vecnormalize.pkl
  
체크포인트: 5K, 10K, 15K, ... (5K 간격)
```

---

## 🤔 미해결 질문

### 1. joint_6의 정체

```
질문:
  - URDF의 joint_6은 실제 로봇에 존재하는가?
  - 그리퍼 회전 메커니즘과 관련 있는가?
  - 제거해도 학습에 문제없는가?

검증 필요:
  - check_joint_structure.py 실행
  - 실제 로봇 스펙 재확인
  - 제조사 문의
```

### 2. GRIP 조건 적정성

```
질문:
  - 3cm가 너무 엄격한가?
  - 3.5cm나 4cm가 더 합리적인가?
  - Curriculum으로 점진적 강화가 나은가?

검증 필요:
  - v3.8.1 학습 결과 대기
  - 300K에서 GRIP 20-30% 달성 여부
  - 달성 못하면 3.5cm로 완화 고려
```

### 3. 학습 시간

```
질문:
  - 300K로 LIFT 달성 가능한가?
  - 500K나 1M까지 필요한가?
  - Curriculum이 더 효율적인가?

검증 필요:
  - 300K 결과 분석
  - LIFT 10% 이상이면 성공
  - 미달 시 연장 or 조건 완화
```

---

## 📚 참고 자료

### 공식 문서

- Waveshare RoArm-M3 Wiki: https://www.waveshare.com/wiki/RoArm-M3
- Isaac Sim Documentation: https://docs.omniverse.nvidia.com/isaacsim/
- Stable Baselines3 PPO: https://stable-baselines3.readthedocs.io/

### 프로젝트 문서

- `README.md`: 프로젝트 개요
- `docs/REFERENCES.md`: 전체 참고 자료 모음
- `resources/roarm_m3/waveshare_wiki_summary.md`: RoArm-M3 스펙

### 예제 코드

- `resources/roarm_m3/RoArm-M3_example-250108/`: 공식 예제
- `RoArm-M3_module.h`: 조인트 제어 함수
- `RoArm-M3_config.h`: 하드웨어 파라미터

---

## 🎯 핵심 교훈

### 1. 보상 설계의 중요성

> "좋은 지표가 나쁜 행동을 만들 수 있다"

- GRIP 38%이지만 실제로는 0%
- 지표만 보고 판단하면 안 됨
- Visual verification 필수

### 2. 시뮬레이션의 한계

> "모든 모델은 틀렸지만, 일부는 유용하다"

- URDF가 실제와 다를 수 있음
- joint_6 같은 오류 존재 가능
- 지속적인 검증 필요

### 3. 점진적 개선의 힘

> "완벽한 조건보다 빠른 피드백"

- v3.7 → v3.8.0 → v3.8.1 진화
- 각 버전에서 문제 발견 및 해결
- Iterative improvement

---

## ✅ 오늘의 성과 체크리스트

- [x] GRIP 조건 강화 (v3.8.1)
- [x] 조인트 구조 분석 완료
- [x] 문서 3개 작성
- [x] 진단 도구 개발
- [x] v3.8.1 학습 시작 (진행 중)
- [ ] 학습 완료 대기 (예정)
- [ ] GUI 검증 (예정)
- [ ] 조인트 검증 (예정)

---

## 🌙 내일 할 일

1. **v3.8.1 학습 결과 분석**
   - 300K 완료 확인
   - GUI 재생으로 실제 행동 검증
   - GRIP/LIFT 달성 여부 평가

2. **조인트 구조 검증**
   - `check_joint_structure.py` 실행
   - joint_6 움직임 관찰
   - URDF 수정 필요성 판단

3. **다음 학습 계획 수립**
   - v3.8.1 결과에 따라 결정
   - URDF 수정 (v3.8.2) vs 연장 학습 (500K)
   - Curriculum Learning 도입 검토

---

**작성자**: GitHub Copilot  
**작성일**: 2025-10-24 21:00  
**환경**: RoArm-M3 + Isaac Sim 5.0 + PPO  
**버전**: v3.8.1 (GRIP Strengthening)
